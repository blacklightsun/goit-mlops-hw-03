**Inference-сервіс для розпізнавання об'єктів на фото**

**Стек**: python-скрипт з TorchScript-моделлю MobileNet_V2, що запускається в контейнері.

Для створення docker-образу з репозиторію необхідно:

1. Завантажити в папку проекта файли з репозиторію.
2. Запустити bash-скрипт install_dev_tools.sh, який встановить необхідні інстременти (docker, docker compose, python, pip) та необхідні пакети (torch, torchvision, pillow, Django). Пакет Django не є необхідним для python-скрипта, додається для виконання умов ДЗ))((. Якщо якісь з цих інструментів чи/або пакетів вже встановлені - вони не перевстановлюються. Якщо версія python менша за 3.9 - вона оновлюється до новішої версії. Версії інструментів та пакетів логуються в файл install.log.
3. Необхідні python-пакети встановлюються в віртуальне оточення в папку .venv в папці проекту.
4. Для інференсу використовується модель MobileNet_V2, яка трасована у TorchScript-файл (model/traced_model.pt). Human-назви класів збережені в файл model/class_names.txt.
5. Скрипт для інференсу - у файлі app/inference.py, який виводить передбачення для образу з фото, зазначаючи TOP-3 найймовірніших класи.
6. Реалізовано декілька варіантів docker-образів для сервісу:
- fat, де образ побудований на базі образі образу python:3.9;
- slim, де образ побудований на базі образі образу python:3.11-slim з бінарними файлами python-пакетів у вигляді whl-файлів;
- multistage, де build-stage побудований на базі образі образу python:3.11-slim з бінарними файлами python-пакетів у вигляді whl-файлів, а runtime-stage - на базі python:3.11-slim та скопійоваго з build-stage готового віртуального оточення, в якому pytorch обрізано для використання тільки на CPU;
- onnx - де образ побудовано на базі образу python:3.11-slim, а у якості runtime-двигуна для інференсу використовується onnxruntime та конвертована у формат ONNX модель. Скрипт конвертації моделі - у файлі pt_to_onnx_convert.py, файл з назвами класів - той же. Скрипт для інференсу окремий - app/onnx_inference.py. Цей образ не містить pytorch-пакет у своєму складі.
7. Команди для створення образів по цим варіантам та запуску інференсу по ним наведені у файлі docker_commands.txt.
8. Ці варіанти образів мають однаковий функціонал, але мають різний час збірки та зайнятий простір на диску:

|REPOSITORY              |   SIZE |STAGE QUANTITY|
|:-----------------------|-------:|-------------:|
|pytorch-infer-fat       |  7.98GB|1             |
|pytorch-infer-slim      |  1.52GB|1             |
|pytorch-infer-multistage|  1.08GB|2             |
|pytorch-infer-onnx      |   619MB|1             |


Відповідно, чим менший розмір образу, тим менше в ньому зайвих інструментів та сервісів. Зайві інструменти не використовуються для виконання задач сервісу, але займають зайве місце та уповільнюють збірку образу, при цьому сама модель (ваги моделі) займає 14.5 Мб (ONNX-версія - 14 Мб).

9. Напрями експериментів для подальшого зменшення розміру образів:
- побудова образів на базі distroless-образів. У мене distroless не запрацював, бо distroless не може знайти динамічні бібліотеки PyTorch, які залежать від libc та інших системних бібліотек. Перспективним варіантом на цьому шляху бачу використання onnxruntime з distroless-образами - можливо в такому поєднанні runtime буде простіший і запрацює на спрощеному образі;
- використання полегшених pytorch-пакетів.



